# -*- coding: utf-8 -*-
import os, glob, re, unicodedata, warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder

# ===========================
# 0) ê¸°ë³¸ ì„¤ì •
# ===========================
SEED = 42
TEST_RATIO = 0.2

# ===========================
# 1) CSV ìë™ íƒìƒ‰
# ===========================
csv_files = glob.glob("*.csv")
if not csv_files:
    raise FileNotFoundError("âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

csv_files = [(f, os.path.getsize(f)) for f in csv_files]
csv_files.sort(key=lambda x: x[1], reverse=True)
CSV_PATH = csv_files[0][0]
print(f"[ìë™ì„ íƒ] CSV íŒŒì¼: {CSV_PATH} ({csv_files[0][1]/1024/1024:.2f} MB)")

# ===========================
# 2) ë°ì´í„° ë¡œë“œ & ì»¬ëŸ¼ ë§¤í•‘
# ===========================
df = pd.read_csv(CSV_PATH)

def normalize_col(s: str) -> str:
    s = unicodedata.normalize("NFC", str(s))
    s = s.replace("ã¡", "m2").replace("Â²", "2")
    s = s.strip().lower()
    s = re.sub(r"\s+", "", s)
    s = re.sub(r"[()\[\]{}]", "", s)
    s = s.replace("/", "").replace("-", "").replace(".", "").replace(",", "")
    return s

def pick_col(df_cols, include_keywords, exclude_keywords=None):
    exclude_keywords = exclude_keywords or []
    norm_map = {col: normalize_col(col) for col in df_cols}
    for col, norm in norm_map.items():
        if any(ex in norm for ex in exclude_keywords):
            continue
        if any(inc in norm for inc in include_keywords):
            return col
    return None

PRICE_INCL = ["ê±°ë˜ê¸ˆì•¡ë§Œì›", "ê±°ë˜ê¸ˆì•¡", "ì‹¤ê±°ë˜ê°€", "ë§¤ë§¤ê¸ˆì•¡", "ê¸ˆì•¡"]
PRICE_EXCL = ["ë³´ì¦ê¸ˆ", "ì›”ì„¸", "ì „ì„¸", "ê´€ë¦¬ë¹„"]
AREA_INCL  = ["ì „ìš©ë©´ì m2", "ì „ìš©ë©´ì ", "ë©´ì "]
FLOOR_INCL = ["ì¸µ"]
DATE_INCL  = ["ê±°ë˜ì¼ì", "ê³„ì•½ì¼ì", "ì‹ ê³ ì¼"]
DATE_EXCL  = ["ì¡°íšŒì—°ì›”", "ì¡°íšŒì¼"]

price_col = pick_col(df.columns, PRICE_INCL, PRICE_EXCL)
area_col  = pick_col(df.columns, AREA_INCL)
floor_col = pick_col(df.columns, FLOOR_INCL)
date_col  = pick_col(df.columns, DATE_INCL, DATE_EXCL)

# ===========================
# 3) ì „ì²˜ë¦¬
# ===========================
df[price_col] = (
    df[price_col].astype(str)
                  .str.replace(",", "", regex=False)
                  .str.replace(" ", "", regex=False)
)
df = df[df[price_col].str.match(r"^\d+$", na=False)]
df[price_col] = df[price_col].astype(np.int64)

df[area_col] = pd.to_numeric(df[area_col], errors="coerce")
df[floor_col] = pd.to_numeric(df[floor_col], errors="coerce")
df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

df = df.dropna(subset=[price_col, area_col, floor_col, date_col]).copy()
df["year"] = df[date_col].dt.year.astype(int)
df["month"] = df[date_col].dt.month.astype(int)
df["ì—°ì‹"] = df["year"] - pd.to_numeric(df["ê±´ì¶•ë…„ë„"], errors="coerce")

# ë²”ì£¼í˜• ì²˜ë¦¬
cat_features = ["ì‹œêµ°êµ¬ëª…", "ë²•ì •ë™", "ì•„íŒŒíŠ¸ëª…"]
for col in cat_features:
    if col in df.columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))
    else:
        df[col] = 0

features = [area_col, floor_col, "ì—°ì‹", "year", "month"] + cat_features
X = df[features]
y = df[price_col]

# ===========================
# 4) Train/Test Split (ì‹œê°„ìˆœ)
# ===========================
df_sorted = df.sort_values(by=date_col)
split_idx = int(len(df_sorted) * (1 - TEST_RATIO))
train_idx, test_idx = df_sorted.index[:split_idx], df_sorted.index[split_idx:]

X_train, X_test = X.loc[train_idx], X.loc[test_idx]
y_train, y_test = y.loc[train_idx], y.loc[test_idx]

print(f"[ë¶„í• ] Train={len(X_train):,} / Test={len(X_test):,}")

# ===========================
# 5) ëª¨ë¸ í•™ìŠµ & í‰ê°€
# ===========================
models = {
    "Ridge": Ridge(alpha=1.0),
    "RandomForest": RandomForestRegressor(n_estimators=200, random_state=SEED, n_jobs=-1),
    "XGBoost": XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=6,
                            n_jobs=-1, random_state=SEED),
    "LightGBM": LGBMRegressor(n_estimators=600, learning_rate=0.05,
                              random_state=SEED, n_jobs=-1),
    "CatBoost": CatBoostRegressor(iterations=500, depth=6, learning_rate=0.05,
                                  random_state=SEED, verbose=0)
}

results = {}

for name, model in models.items():
    try:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        mae = mean_absolute_error(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        r2 = r2_score(y_test, y_pred)

        results[name] = {"MAE": mae, "RMSE": rmse, "MAPE": mape, "R2": r2}

    except Exception as e:
        print(f"[{name} ì‹¤íŒ¨] {e}")

# ===========================
# 6) ê²°ê³¼ í‘œ
# ===========================
results_df = pd.DataFrame(results).T
results_df = results_df[["MAE", "RMSE", "MAPE", "R2"]]
print("\n=== ëª¨ë¸ ë¹„êµ ê²°ê³¼ ===")
print(results_df)

# ===========================
# 7) ê·¸ë˜í”„
# ===========================
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

axes[0].bar(results_df.index, results_df["MAE"], color="skyblue")
axes[0].set_title("MAE (ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)")
axes[0].set_ylabel("ë§Œì›")

axes[1].bar(results_df.index, results_df["RMSE"], color="orange")
axes[1].set_title("RMSE (ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)")
axes[1].set_ylabel("ë§Œì›")

axes[2].bar(results_df.index, results_df["R2"], color="green")
axes[2].set_title("RÂ² (í´ìˆ˜ë¡ ì¢‹ìŒ)")
axes[2].set_ylabel("Score")

plt.tight_layout()
plt.savefig("model_comparison.png")
plt.close()

print("\nğŸ“Š ë¹„êµ ê·¸ë˜í”„ ì €ì¥: model_comparison.png")